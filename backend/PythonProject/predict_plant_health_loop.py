import cv2
import os
import time
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import requests
import tensorflow as tf
import numpy as np

# âœ… è®¾å¤‡é…ç½®
device_id = "RPi-01"
server_url = "http://10.20.135.28:5000/upload"  # âœ… æ­£ç¡®åœ°å€
capture_interval = 30  # æ¯ 30 ç§’æ‰§è¡Œä¸€æ¬¡

# âœ… ç±»åˆ«æ ‡ç­¾
class_names = [
    "Pepper__bell___Bacterial_spot",
    "Pepper__bell___healthy",
    "Potato___Early_blight",
    "Potato___healthy",
    "Potato___Late_blight",
    "Tomato__Target_Spot",
    "Tomato__Tomato_mosaic_virus",
    "Tomato__Tomato_YellowLeaf__Curl_Virust",
    "Tomato_Bacterial_spot",
    "Tomato_Early_blight",
    "Tomato_healthy",
    "Tomato_Late_blight",
    "Tomato_Leaf_Mold",
    "Tomato_Septoria_leaf_spot",
    "Tomato_Spider_mites_Two_spotted_spider_mite"
]

growth_classes = ["seedling", "mature"]

# âœ… PyTorch è®¾ç½®
torch_device = torch.device("cpu")
num_classes = len(class_names)
torch_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

pytorch_model = models.resnet18()
pytorch_model.fc = nn.Linear(pytorch_model.fc.in_features, num_classes)
pytorch_model.load_state_dict(torch.load("bestone_0.2698.pth", map_location=torch_device))
pytorch_model = pytorch_model.to(torch_device)
pytorch_model.eval()

# âœ… TensorFlow è®¾ç½®
tf_model = tf.keras.models.load_model("plant_growth_model.h5")

print("ğŸš€ å¼€å§‹å¾ªç¯ï¼Œæ¯éš” 30 ç§’æ‹ç…§è¯†åˆ«å¹¶ä¸Šä¼ ï¼ˆå«å›¾ç‰‡ï¼‰...\næŒ‰ Ctrl+C åœæ­¢")

while True:
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    safe_timestamp = timestamp.replace(":", "-").replace(" ", "_")
    img_path = f"plant_{safe_timestamp}.jpg"

    # ğŸ“¸ æ‹ç…§
    cap = cv2.VideoCapture(0)
    ret, frame = cap.read()
    if ret:
        cv2.imwrite(img_path, frame)
        print(f"\nğŸ“· æ‹æ‘„æˆåŠŸï¼š{img_path}")
    else:
        print("âŒ æ‘„åƒå¤´æ‹ç…§å¤±è´¥")
        cap.release()
        time.sleep(capture_interval)
        continue
    cap.release()

    # ğŸŒ¿ å¥åº·çŠ¶æ€é¢„æµ‹ï¼ˆPyTorchï¼‰
    image_pil = Image.open(img_path).convert("RGB")
    input_tensor = torch_transform(image_pil).unsqueeze(0).to(torch_device)
    with torch.no_grad():
        output = pytorch_model(input_tensor)
        _, pred = torch.max(output, 1)
        health_status = class_names[pred.item()]
    print(f"ğŸŒ¿ å¥åº·çŠ¶æ€è¯†åˆ«ç»“æœï¼š{health_status}")

    # ğŸŒ± ç”Ÿé•¿é˜¶æ®µé¢„æµ‹ï¼ˆTensorFlowï¼‰
    img = cv2.imread(img_path)
    img_resized = cv2.resize(img, (224, 224)) / 255.0
    img_input = np.expand_dims(img_resized, axis=0)
    growth_pred = tf_model.predict(img_input, verbose=0)[0]
    growth_label = growth_classes[np.argmax(growth_pred)]
    print(f"ğŸŒ± ç”Ÿé•¿é˜¶æ®µè¯†åˆ«ç»“æœï¼š{growth_label}")

    # ğŸ“¤ ä¸Šä¼ æ•°æ®å‡†å¤‡
    payload = {
        "deviceID": device_id,
        "timestamp": timestamp,
        "prediction": health_status,
        "growthStage": growth_label
    }

    # ğŸ›œ ä¸Šä¼  + é‡è¯•é€»è¾‘
    max_retries = 3
    success = False
    for attempt in range(max_retries):
        try:
            with open(img_path, "rb") as image_file:
                files = {"image": image_file}
                response = requests.post(server_url, data=payload, files=files, timeout=5)

            if response.status_code == 200:
                print(f"âœ… ä¸Šä¼ æˆåŠŸï¼š{response.status_code} - {response.text}")
                success = True
                break
            else:
                print(f"âš ï¸ ä¸Šä¼ å¤±è´¥ï¼ˆçŠ¶æ€ç  {response.status_code}ï¼‰ï¼š{response.text}")
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡ä¸Šä¼ å¤±è´¥ï¼š{e}")
            time.sleep(2)

    # âœ… æˆåŠŸååˆ é™¤å›¾ç‰‡
    if success:
        os.remove(img_path)
        print(f"ğŸ§¹ å·²åˆ é™¤å›¾ç‰‡ï¼š{img_path}")
    else:
        print(f"ğŸš« æœ¬è½®ä¸Šä¼ å¤±è´¥ï¼Œä¿ç•™å›¾ç‰‡ä»¥ä¾¿æ’æŸ¥")

    time.sleep(capture_interval)

